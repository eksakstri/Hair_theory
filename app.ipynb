{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tnbFQfb0Emha"
   },
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, refine_landmarks=True)\n",
    "\n",
    "def get_keypoints(image):\n",
    "    img_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(img_rgb)\n",
    "\n",
    "    if not results.multi_face_landmarks:\n",
    "        return None\n",
    "\n",
    "    landmarks = results.multi_face_landmarks[0].landmark\n",
    "\n",
    "    # Use indexes: left_eye (33), right_eye (263)\n",
    "    left_eye = landmarks[33]\n",
    "    right_eye = landmarks[263]\n",
    "\n",
    "    h, w, _ = image.shape\n",
    "    left_eye = (int(left_eye.x * w), int(left_eye.y * h))\n",
    "    right_eye = (int(right_eye.x * w), int(right_eye.y * h))\n",
    "\n",
    "    return left_eye, right_eye\n",
    "\n",
    "def align_face(image):\n",
    "    left_eye, right_eye = get_keypoints(image)\n",
    "    eye_center = ((left_eye[0] + right_eye[0]) // 2,\n",
    "                  (left_eye[1] + right_eye[1]) // 2)\n",
    "\n",
    "    dx = right_eye[0] - left_eye[0]\n",
    "    dy = right_eye[1] - left_eye[1]\n",
    "    angle = np.degrees(np.arctan2(dy, dx))\n",
    "\n",
    "    M = cv2.getRotationMatrix2D(eye_center, angle, 1)\n",
    "    aligned = cv2.warpAffine(image, M, (image.shape[1], image.shape[0]),\n",
    "                             flags=cv2.INTER_CUBIC)\n",
    "    return aligned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30558,
     "status": "ok",
     "timestamp": 1765216048837,
     "user": {
      "displayName": "Saksham Tripathi",
      "userId": "07312562530547297805"
     },
     "user_tz": -330
    },
    "id": "nCUm7rZR7jmB",
    "outputId": "032bad27-8398-4e97-97ef-6d5d3652aac0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:6001\n",
      " * Running on http://172.28.0.12:6001\n",
      "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "INFO:werkzeug: * Restarting with watchdog (inotify)\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "from PIL import Image\n",
    "import mediapipe\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "from flask import Flask, request, jsonify\n",
    "import base64\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "def images_to_base64_dict(cropped_objects):\n",
    "    base64_dict = {}\n",
    "    for cls_name, img in cropped_objects.items():\n",
    "        _, buffer = cv2.imencode('.jpg', img)\n",
    "        img_base64 = base64.b64encode(buffer).decode('utf-8')\n",
    "        base64_dict[cls_name] = img_base64\n",
    "    return base64_dict\n",
    "\n",
    "def focal_loss(gamma=2., alpha=0.25):\n",
    "    def loss(y_true, y_pred):\n",
    "        y_pred = tf.clip_by_value(y_pred, 1e-7, 1 - 1e-7)\n",
    "        ce = -y_true * tf.math.log(y_pred)\n",
    "        weight = alpha * tf.pow(1 - y_pred, gamma)\n",
    "        return tf.reduce_sum(weight * ce, axis=-1)\n",
    "    return loss\n",
    "\n",
    "def normalize_hsv(image_bgr):\n",
    "    image_hsv = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2HSV).astype(np.float32)\n",
    "    image_hsv[..., 0] /= 179.0\n",
    "    image_hsv[..., 1] /= 255.0\n",
    "    image_hsv[..., 2] /= 255.0\n",
    "    return image_hsv\n",
    "\n",
    "def pred(image):\n",
    "    image = align_face(image)\n",
    "    model = YOLO('best.pt')\n",
    "    results = model(image)\n",
    "    cropped_objects = {}\n",
    "\n",
    "    for result in results:\n",
    "        boxes = result.boxes\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "\n",
    "            cls_id = int(box.cls[0].item())\n",
    "            cls_name = model.names[cls_id]\n",
    "            crop_img = image[y1:y2, x1:x2].copy()\n",
    "\n",
    "            cropped_objects[cls_name] = crop_img\n",
    "\n",
    "    copy = cropped_objects.copy()\n",
    "\n",
    "    if 'lear' not in cropped_objects.keys():\n",
    "        cropped_objects['lear'] = cv2.flip(cropped_objects['rear'],1)\n",
    "\n",
    "    if 'rear' not in cropped_objects.keys():\n",
    "        cropped_objects['rear'] = cv2.flip(cropped_objects['lear'],1)\n",
    "\n",
    "    keys_order = [\"lear\", \"hairs\", \"rear\"]\n",
    "    images = [cropped_objects[k] for k in keys_order if k in cropped_objects]\n",
    "    max_height = max(img.shape[0] for img in images)\n",
    "\n",
    "    padded_images = []\n",
    "    for img in images:\n",
    "        h, w, _ = img.shape\n",
    "        top_pad = (max_height - h) // 2\n",
    "        bottom_pad = max_height - h - top_pad\n",
    "\n",
    "        padded = cv2.copyMakeBorder(img, top_pad, bottom_pad, 0, 0,\n",
    "                                    borderType=cv2.BORDER_CONSTANT,\n",
    "                                    value=(0, 0, 0))\n",
    "        padded_images.append(padded)\n",
    "\n",
    "    cropped_objects['forehead'] = cv2.hconcat(padded_images)\n",
    "    resize_shape = (128, 128)\n",
    "    type_img = cv2.resize(cropped_objects['forehead'], resize_shape)\n",
    "    gray = cv2.cvtColor(type_img, cv2.COLOR_BGR2GRAY)\n",
    "    all = cv2.Canny(gray, threshold1=80, threshold2=120)\n",
    "    all = np.expand_dims(all, axis=-1)\n",
    "    all = np.expand_dims(all, axis=0)\n",
    "    col = cv2.cvtColor(type_img, cv2.COLOR_RGB2HSV)\n",
    "    col = normalize_hsv(col)\n",
    "    col = np.expand_dims(col, axis=0)\n",
    "    all = all.astype(np.float32) / 255.0\n",
    "\n",
    "    beard_model = load_model(\"Beard_1757324749.keras\", custom_objects={'custom_loss': focal_loss})\n",
    "    col_model = load_model(\"Col_1757327821.keras\")\n",
    "    len_model = load_model(\"Length_1757331097.keras\", custom_objects={'custom_loss': focal_loss})\n",
    "    must_model = load_model(\"Must_1757333090.keras\", custom_objects={'custom_loss': focal_loss})\n",
    "    type_model = load_model(\"Type_1757390267.keras\", custom_objects={'custom_loss': focal_loss})\n",
    "\n",
    "    beard = ['clean', 'full', 'mid', 'short']\n",
    "    color = ['black', 'blonde', 'brown', 'none', 'red', 'white']\n",
    "    length = ['bald', 'full', 'mid', 'short']\n",
    "    must = ['clean', 'full', 'mid', 'short']\n",
    "    type = ['curly', 'none', 'straight', 'wavy']\n",
    "    beard_pred = beard_model.predict(all)\n",
    "    col_pred = col_model.predict(col)\n",
    "    len_pred = len_model.predict(all)\n",
    "    must_pred = must_model.predict(all)\n",
    "    type_pred = type_model.predict(all)\n",
    "\n",
    "    result = images_to_base64_dict(copy)\n",
    "\n",
    "    result[\"beard_name\"] =  beard[np.argmax(beard_pred)]\n",
    "    result[\"color_name\"] =  color[np.argmax(col_pred)]\n",
    "    result[\"length_name\"] =  length[np.argmax(len_pred)]\n",
    "    result[\"moustache_name\"] =  must[np.argmax(must_pred)]\n",
    "    result[\"type_name\"] =  type[np.argmax(type_pred)]\n",
    "\n",
    "    return result\n",
    "\n",
    "@app.route('/pred', methods=['POST'])\n",
    "def pred_api():\n",
    "    data = request.get_json()\n",
    "    base64_str = data['image']\n",
    "    img_data = base64.b64decode(base64_str)\n",
    "    np_arr = np.frombuffer(img_data, np.uint8)\n",
    "    image = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)\n",
    "    return pred(image)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0',debug=True, port = 6001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1bbuvvJfZjqE"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOxZ/SVKMZWZH79nO32/KxA",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
